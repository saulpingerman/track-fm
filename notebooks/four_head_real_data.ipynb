{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf91ec2b-1cc4-4449-9332-66623845cd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user\n",
      "Found 2 parquet files:\n",
      "  data/cleaned_partitioned_ais/year=2025/month=2/day=2/part-0.parquet\n",
      "  data/cleaned_partitioned_ais/year=2025/month=2/day=1/part-0.parquet\n"
     ]
    }
   ],
   "source": [
    "%cd /home/ec2-user\n",
    "import glob\n",
    "\n",
    "matches = glob.glob(\"data/cleaned_partitioned_ais/*/*/*/*.parquet\")\n",
    "print(f\"Found {len(matches)} parquet files:\")\n",
    "for p in matches[:10]:\n",
    "    print(\" \", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61be75e7-3fe9-4759-9cd4-289f571526c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user\n",
      "🟢 Cell start: loading data\n",
      "🟡 Entering load_cleaned_data()\n",
      "    Looking under /home/ec2-user/data/cleaned_partitioned_ais\n",
      "    Found 2 parquet files\n",
      "    Reading into Polars...\n",
      "🟢 Loaded DataFrame: 19082312 rows, 9 cols\n",
      "🟢 Starting training\n",
      "🟡 Training on device: cuda\n",
      "🟡 Initializing streaming dataset\n",
      "🟢 Dataset init: 3866 vessels in 2.8s\n",
      "🟢 DataLoader ready with batch_size=64\n",
      "🟡 Building model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/miniconda3/envs/four_head/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🟢 Model built\n",
      "\n",
      "🟡 Epoch 1/100 start\n",
      "    [Epoch 1] Batch 50 NLL -6.5805\n",
      "    [Epoch 1] Batch 100 NLL -8.7749\n",
      "    [Epoch 1] Batch 150 NLL -9.7512\n",
      "    [Epoch 1] Batch 200 NLL -10.2883\n",
      "    [Epoch 1] Batch 250 NLL -10.6036\n",
      "    [Epoch 1] Batch 300 NLL -5.0510\n",
      "    [Epoch 1] Batch 350 NLL -9.2293\n",
      "    [Epoch 1] Batch 400 NLL -10.1182\n",
      "    [Epoch 1] Batch 450 NLL -10.5253\n",
      "    [Epoch 1] Batch 500 NLL -10.7483\n",
      "    [Epoch 1] Batch 550 NLL -10.8768\n",
      "    [Epoch 1] Batch 600 NLL -8.7911\n",
      "    [Epoch 1] Batch 650 NLL -10.1051\n",
      "    [Epoch 1] Batch 700 NLL -10.5682\n",
      "    [Epoch 1] Batch 750 NLL -10.7944\n",
      "    [Epoch 1] Batch 800 NLL -10.9186\n",
      "    [Epoch 1] Batch 850 NLL -7.2878\n",
      "    [Epoch 1] Batch 900 NLL -9.8364\n",
      "    [Epoch 1] Batch 950 NLL -10.4597\n",
      "    [Epoch 1] Batch 1000 NLL -10.7429\n",
      "    [Epoch 1] Batch 1050 NLL -10.8915\n",
      "    [Epoch 1] Batch 1100 NLL -10.9725\n",
      "    [Epoch 1] Batch 1150 NLL -11.0187\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 135\u001b[0m\n\u001b[1;32m    132\u001b[0m df \u001b[38;5;241m=\u001b[39m load_cleaned_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/cleaned_partitioned_ais\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🟢 Starting training\u001b[39m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 135\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43md_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnhead\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mff_hidden\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfourier_m\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\n\u001b[1;32m    147\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🟢 Training complete\u001b[39m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[2], line 121\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(df, seq_len, d_model, nhead, num_layers, ff_hidden, fourier_m, rank, batch_size, lr, epochs, device)\u001b[0m\n\u001b[1;32m    118\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m(pdf \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-12\u001b[39m)\u001b[38;5;241m.\u001b[39mlog()\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    119\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad(); loss\u001b[38;5;241m.\u001b[39mbackward(); opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 121\u001b[0m total_nll \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m xb\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    122\u001b[0m count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m xb\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m50\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%cd /home/ec2-user\n",
    "# ─── 1) Setup imports & module path ──────────────────────────────────────────\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# add your Fourier head module to path\n",
    "fourier_dir = Path.home() / \"repos\" / \"fourier-head\" / \"notebooks\"\n",
    "sys.path.insert(0, str(fourier_dir))\n",
    "\n",
    "import polars as pl\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "\n",
    "from four_head_2D_LR import FourierHead2DLR  # your FourierHead2D_FFT implementation\n",
    "\n",
    "# ─── 2) Data loading helper ─────────────────────────────────────────────────\n",
    "def load_cleaned_data(cleaned_root: str) -> pl.DataFrame:\n",
    "    print(\"🟡 Entering load_cleaned_data()\", flush=True)\n",
    "    p = Path(cleaned_root).resolve()\n",
    "    print(f\"    Looking under {p}\", flush=True)\n",
    "    files = list(p.rglob(\"*.parquet\"))\n",
    "    print(f\"    Found {len(files)} parquet files\", flush=True)\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No parquet files under {p}\")\n",
    "    print(\"    Reading into Polars...\", flush=True)\n",
    "    df = pl.read_parquet([str(f) for f in files])\n",
    "    print(f\"🟢 Loaded DataFrame: {df.height} rows, {len(df.columns)} cols\", flush=True)\n",
    "    return df\n",
    "\n",
    "# ─── 3) Streaming dataset ───────────────────────────────────────────────────\n",
    "class AISForecastIterableDataset(IterableDataset):\n",
    "    \"\"\"\n",
    "    Streams windows of past->next positions, one vessel at a time.\n",
    "    \"\"\"\n",
    "    def __init__(self, df: pl.DataFrame, seq_len: int = 10):\n",
    "        print(\"🟡 Initializing streaming dataset\", flush=True)\n",
    "        start = time.time()\n",
    "        # normalize coordinates\n",
    "        df = df.with_columns([\n",
    "            (pl.col(\"lat\") / 90.0).alias(\"lat_n\"),\n",
    "            (pl.col(\"lon\") / 180.0).alias(\"lon_n\"),\n",
    "        ])\n",
    "        self.df = df.sort([\"mmsi\", \"timestamp\"])\n",
    "        self.mmsis = self.df[\"mmsi\"].unique().to_list()\n",
    "        self.seq_len = seq_len\n",
    "        print(f\"🟢 Dataset init: {len(self.mmsis)} vessels in {time.time()-start:.1f}s\", flush=True)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for idx, m in enumerate(self.mmsis, 1):\n",
    "            grp = self.df.filter(pl.col(\"mmsi\") == m).select([\"lat_n\", \"lon_n\"])\n",
    "            coords = torch.tensor(grp.to_numpy(), dtype=torch.float32)\n",
    "            N = coords.size(0)\n",
    "            if N <= self.seq_len:\n",
    "                continue\n",
    "            for i in range(self.seq_len, N):\n",
    "                past   = coords[i-self.seq_len:i]  # (seq_len,2)\n",
    "                target = coords[i]                 # (2,)\n",
    "                yield past, target\n",
    "            if idx % 500 == 0:\n",
    "                print(f\"    [Dataset] streamed {idx}/{len(self.mmsis)} vessels\", flush=True)\n",
    "\n",
    "# ─── 4) Model definition ────────────────────────────────────────────────────\n",
    "class TransformerForecaster(nn.Module):\n",
    "    def __init__(self, seq_len: int, d_model: int, nhead: int,\n",
    "                 num_layers: int, ff_hidden: int, fourier_m: int, rank: int):\n",
    "        super().__init__()\n",
    "        print(\"🟡 Building model\", flush=True)\n",
    "        self.input_proj = nn.Linear(2, d_model)\n",
    "        self.pos_emb = nn.Parameter(torch.randn(seq_len, d_model))\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, ff_hidden)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.fh = FourierHead2DLR(dim_input=d_model, num_frequencies=fourier_m,rank=rank)\n",
    "        print(\"🟢 Model built\", flush=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B, seq_len, 2), targets: (B, 2)\n",
    "        h = self.input_proj(x) + self.pos_emb.unsqueeze(0)   # (B,S,d_model)\n",
    "        h = self.transformer(h.transpose(0,1))               # (S,B,d_model)\n",
    "        last = h[-1]                                         # (B,d_model)\n",
    "        return self.fh(last, targets)                        # (B,)\n",
    "\n",
    "# ─── 5) Training loop ───────────────────────────────────────────────────────\n",
    "def train(\n",
    "    df: pl.DataFrame,\n",
    "    seq_len: int = 10,\n",
    "    d_model: int = 64,\n",
    "    nhead: int = 4,\n",
    "    num_layers: int = 2,\n",
    "    ff_hidden: int = 128,\n",
    "    fourier_m: int = 8,\n",
    "    rank: int = 4,\n",
    "    batch_size: int = 64,\n",
    "    lr: float = 1e-6,\n",
    "    epochs: int = 5,\n",
    "    device: str = None\n",
    "):\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"🟡 Training on device: {device}\", flush=True)\n",
    "\n",
    "    ds = AISForecastIterableDataset(df, seq_len=seq_len)\n",
    "    loader = DataLoader(ds, batch_size=batch_size, shuffle=False,\n",
    "                        drop_last=True, num_workers=0, pin_memory=True)\n",
    "    print(f\"🟢 DataLoader ready with batch_size={batch_size}\", flush=True)\n",
    "\n",
    "    model = TransformerForecaster(seq_len, d_model, nhead, num_layers, ff_hidden, fourier_m, rank)\n",
    "    model.to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for ep in range(1, epochs+1):\n",
    "        print(f\"\\n🟡 Epoch {ep}/{epochs} start\", flush=True)\n",
    "        total_nll = 0.0\n",
    "        count = 0\n",
    "        for batch_i, (xb, yb) in enumerate(loader, 1):\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            pdf = model(xb, yb)\n",
    "            loss = -(pdf + 1e-12).log().mean()\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "\n",
    "            total_nll += loss.item() * xb.size(0)\n",
    "            count += xb.size(0)\n",
    "            if batch_i % 50 == 0:\n",
    "                print(f\"    [Epoch {ep}] Batch {batch_i} NLL {loss.item():.4f}\", flush=True)\n",
    "        avg_nll = total_nll / count\n",
    "        print(f\"🟢 Epoch {ep} done — Avg NLL: {avg_nll:.4f}\", flush=True)\n",
    "\n",
    "    return model\n",
    "\n",
    "# ─── 6) Run everything ───────────────────────────────────────────────────────\n",
    "print(\"🟢 Cell start: loading data\", flush=True)\n",
    "df = load_cleaned_data(\"data/cleaned_partitioned_ais\")\n",
    "\n",
    "print(\"🟢 Starting training\", flush=True)\n",
    "model = train(\n",
    "    df,\n",
    "    seq_len=20,\n",
    "    d_model=128,\n",
    "    nhead=4,\n",
    "    num_layers=4,\n",
    "    ff_hidden=512,\n",
    "    fourier_m=512,\n",
    "    batch_size=64,\n",
    "    lr=1e-3,\n",
    "    epochs=100,\n",
    "    rank = 4\n",
    ")\n",
    "print(\"🟢 Training complete\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecc653f-c517-4fbe-aaf5-8fb97c8c53c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ed480c3-b17f-4b98-aa24-1ae19f09f33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<stdin>\", line 169, in <module>\n",
      "TypeError: unsupported operand type(s) for |: 'type' and 'NoneType'\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'# \\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80 cell: end-to-end local-window training \\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\n# Run this once; it replaces the previous \\xe2\\x80\\x9cglobal PDF\\xe2\\x80\\x9d cell.\\nset -euo pipefail\\npython - <<\\'PY\\'\\n# ------------------------------------------------------------\\n# 0) Imports  (all standard \\xe2\\x80\\x93 nothing beyond PyTorch & Polars)\\n# ------------------------------------------------------------\\nimport sys, time, math\\nfrom pathlib import Path\\n\\nimport polars as pl\\nimport torch\\nfrom torch import nn, optim\\nfrom torch.utils.data import IterableDataset, DataLoader\\n\\n# Make sure the Fourier-head repo is on path\\nfourier_dir = Path.home() / \"repos\" / \"fourier-head\" / \"notebooks\"\\nsys.path.insert(0, str(fourier_dir))\\nfrom four_head_2D_LR import FourierHead2DLR   # low-rank Fourier head\\n\\n# ============================================================\\n# 1) Utility: lat/lon  \\xe2\\x86\\x92  local (u,v)  in [-1,1]\\xc2\\xb2\\n# ============================================================\\ndef latlon_to_local_uv(lat, lon, lat0, lon0, half_side_mi=50.0):\\n    \"\"\"\\n    lat, lon, lat0, lon0  : tensors in **degrees**  (any shape \\xe2\\x80\\xa6)\\n    Returns:\\n        uv    : (..., 2)  where each component is in [-1,1]  (clipped)\\n        logJ  : (...)    log-Jacobian \\xce\\x94(area_u,v) \\xe2\\x86\\x92 \\xce\\x94(area_lat,lon)\\n    \"\"\"\\n    lat_rad   = torch.deg2rad(lat)\\n    lat0_rad  = torch.deg2rad(lat0)\\n\\n    # miles per degree (\\xe2\\x89\\x88 69 mi) and longitude scaling with cos(lat)\\n    R_mi      = 69.0\\n    dx_mi     = R_mi * torch.cos(lat0_rad) * (lon - lon0)\\n    dy_mi     = R_mi * (lat - lat0)\\n\\n    u         = dx_mi / half_side_mi\\n    v         = dy_mi / half_side_mi\\n\\n    # ---------- Jacobian |\\xe2\\x88\\x82(x,y)/\\xe2\\x88\\x82(u,v)| = (half_side_mi)\\xc2\\xb2\\n    # plus lat scaling factors (R cos\\xcf\\x86, R)\\n    logJ      = (\\n        -2 * math.log(half_side_mi)\\n        - torch.log(R_mi * torch.cos(lat0_rad))\\n        - math.log(R_mi)\\n    )\\n\\n    # ----- Option A: clip targets that wander outside the window\\n    u_clipped = torch.clamp(u, -1.0, 1.0)\\n    v_clipped = torch.clamp(v, -1.0, 1.0)\\n    uv        = torch.stack([u_clipped, v_clipped], dim=-1)\\n    return uv, logJ\\n\\n# ============================================================\\n# 2) Load all cleaned-AIS parquet shards\\n# ============================================================\\ndef load_cleaned_data(cleaned_root: str) -> pl.DataFrame:\\n    p = Path(cleaned_root).resolve()\\n    files = list(p.rglob(\"*.parquet\"))\\n    if not files:\\n        raise FileNotFoundError(f\"No parquet files under {p}\")\\n    print(f\"\\xf0\\x9f\\x9f\\xa2 Reading {len(files)} parquet file(s)\\xe2\\x80\\xa6\", flush=True)\\n    return pl.read_parquet([str(f) for f in files])\\n\\n# ============================================================\\n# 3) Streaming dataset  (local-window version)\\n# ============================================================\\nclass AISForecastIterableDataset(IterableDataset):\\n    def __init__(self, df: pl.DataFrame, seq_len: int = 10, half_side_mi=50.0):\\n        start = time.time()\\n        self.df = df.sort([\"mmsi\", \"timestamp\"])\\n        self.mmsis = self.df[\"mmsi\"].unique().to_list()\\n        self.seq_len = seq_len\\n        self.half_side_mi = half_side_mi\\n        print(f\"\\xf0\\x9f\\x9f\\xa2 Dataset: {len(self.mmsis)} vessels loaded in {time.time()-start:.1f}s\", flush=True)\\n\\n    def __iter__(self):\\n        for m in self.mmsis:\\n            grp = (\\n                self.df\\n                .filter(pl.col(\"mmsi\") == m)\\n                .select([\"lat\", \"lon\"])\\n            )\\n            coords = torch.tensor(grp.to_numpy(), dtype=torch.float32)  # (N,2)\\n            N = coords.size(0)\\n            if N <= self.seq_len + 1:\\n                continue\\n\\n            # rolling windows\\n            for i in range(self.seq_len, N - 1):\\n                past_abs = coords[i - self.seq_len : i]   # (S,2)\\n                target_abs = coords[i]                    # (2,)\\n\\n                lat0, lon0 = past_abs[-1]                 # window centre\\n                past_uv, _     = latlon_to_local_uv(\\n                    past_abs[:, 0], past_abs[:, 1],\\n                    lat0, lon0, self.half_side_mi\\n                )\\n                target_uv, logJ = latlon_to_local_uv(\\n                    target_abs[0], target_abs[1],\\n                    lat0, lon0, self.half_side_mi\\n                )\\n\\n                centre_ll_norm = torch.tensor([lat0 / 90.0, lon0 / 180.0])\\n\\n                yield (\\n                    past_uv,              # (S,2)  local motion\\n                    centre_ll_norm,       # (2,)    global context\\n                    target_uv,            # (2,)    local target\\n                    logJ                  # ()      log-Jacobian\\n                )\\n\\n# ============================================================\\n# 4) Model  (local motion + global context)\\n# ============================================================\\nclass TransformerForecaster(nn.Module):\\n    def __init__(\\n        self,\\n        seq_len: int,\\n        d_model: int,\\n        nhead: int,\\n        num_layers: int,\\n        ff_hidden: int,\\n        fourier_m: int,\\n        rank: int,\\n    ):\\n        super().__init__()\\n        self.seq_len = seq_len\\n\\n        # each timestep now has 4 features: (u,v, lat_norm, lon_norm)\\n        self.input_proj = nn.Linear(4, d_model)\\n        self.pos_emb = nn.Parameter(torch.randn(seq_len, d_model))\\n        enc_layer = nn.TransformerEncoderLayer(d_model, nhead, ff_hidden)\\n        self.transformer = nn.TransformerEncoder(enc_layer, num_layers)\\n        self.fh = FourierHead2DLR(\\n            dim_input=d_model,\\n            num_frequencies=fourier_m,\\n            rank=rank\\n        )\\n\\n    def forward(self, past_uv, centre_ll, target_uv):\\n        \"\"\"\\n        past_uv   : (B, S, 2)\\n        centre_ll : (B, 2)\\n        target_uv : (B, 2)\\n        \"\"\"\\n        B, S, _ = past_uv.shape\\n        # repeat centre_lat/lon to every timestep\\n        centre_rep = centre_ll.unsqueeze(1).expand(-1, S, -1)  # (B,S,2)\\n        x = torch.cat([past_uv, centre_rep], dim=-1)           # (B,S,4)\\n        h = self.input_proj(x) + self.pos_emb.unsqueeze(0)     # (B,S,d)\\n        h = self.transformer(h.transpose(0, 1))                # (S,B,d)\\n        last = h[-1]                                           # (B,d)\\n        return self.fh(last, target_uv)                        # (B,)\\n\\n# ============================================================\\n# 5) Training loop\\n# ============================================================\\ndef train(\\n    df: pl.DataFrame,\\n    seq_len: int = 10,\\n    d_model: int = 128,\\n    nhead: int = 4,\\n    num_layers: int = 4,\\n    ff_hidden: int = 512,\\n    fourier_m: int = 512,\\n    rank: int = 4,\\n    batch_size: int = 64,\\n    lr: float = 1e-3,\\n    epochs: int = 5,\\n    device: str | None = None,\\n):\\n    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n    print(f\"\\xf0\\x9f\\x9f\\xa1 Training on {device}\", flush=True)\\n\\n    ds = AISForecastIterableDataset(df, seq_len=seq_len)\\n    loader = DataLoader(\\n        ds, batch_size=batch_size, shuffle=False,\\n        drop_last=True, num_workers=0, pin_memory=True\\n    )\\n    model = TransformerForecaster(\\n        seq_len, d_model, nhead, num_layers,\\n        ff_hidden, fourier_m, rank\\n    ).to(device)\\n    opt = optim.Adam(model.parameters(), lr=lr)\\n\\n    for ep in range(1, epochs + 1):\\n        total_nll, count = 0.0, 0\\n        print(f\"\\\\n\\xf0\\x9f\\x9f\\xa1 Epoch {ep}/{epochs}\", flush=True)\\n\\n        for b_idx, (past_uv, centre_ll, target_uv, logJ) in enumerate(loader, 1):\\n            past_uv   = past_uv.to(device)\\n            centre_ll = centre_ll.to(device)\\n            target_uv = target_uv.to(device)\\n            logJ      = logJ.to(device)\\n\\n            pdf_uv = model(past_uv, centre_ll, target_uv)      # (B,)\\n            # log-pdf in lat/lon space = log(pdf_uv) + logJ\\n            loss   = -(torch.log(pdf_uv + 1e-12) + logJ).mean()\\n\\n            opt.zero_grad()\\n            loss.backward()\\n            opt.step()\\n\\n            total_nll += loss.item() * past_uv.size(0)\\n            count     += past_uv.size(0)\\n            if b_idx % 50 == 0:\\n                print(f\"    Batch {b_idx}  NLL {loss.item():.4f}\", flush=True)\\n\\n        print(f\"\\xf0\\x9f\\x9f\\xa2 Epoch {ep}  Avg NLL: {total_nll / count:.4f}\", flush=True)\\n\\n    return model\\n\\n# ============================================================\\n# 6) Execute\\n# ============================================================\\ndf = load_cleaned_data(\"data/cleaned_partitioned_ais\")\\nmodel = train(\\n    df,\\n    seq_len      = 20,\\n    d_model      = 128,\\n    nhead        = 4,\\n    num_layers   = 4,\\n    ff_hidden    = 512,\\n    fourier_m    = 64,     # local window \\xe2\\x86\\x92 far fewer freqs needed\\n    rank         = 4,\\n    batch_size   = 64,\\n    lr           = 1e-3,\\n    epochs       = 100,\\n)\\nprint(\"\\xe2\\x9c\\x85 Training complete\", flush=True)\\nPY\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbash\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m# ─── cell: end-to-end local-window training ────────────────────────────────\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# Run this once; it replaces the previous “global PDF” cell.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mset -euo pipefail\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mpython - <<\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mPY\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# ------------------------------------------------------------\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# 0) Imports  (all standard – nothing beyond PyTorch & Polars)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# ------------------------------------------------------------\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mimport sys, time, math\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mfrom pathlib import Path\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mimport polars as pl\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mimport torch\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mfrom torch import nn, optim\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mfrom torch.utils.data import IterableDataset, DataLoader\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# Make sure the Fourier-head repo is on path\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mfourier_dir = Path.home() / \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrepos\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m / \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfourier-head\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m / \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnotebooks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43msys.path.insert(0, str(fourier_dir))\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mfrom four_head_2D_LR import FourierHead2DLR   # low-rank Fourier head\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# ============================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# 1) Utility: lat/lon  →  local (u,v)  in [-1,1]²\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# ============================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mdef latlon_to_local_uv(lat, lon, lat0, lon0, half_side_mi=50.0):\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    lat, lon, lat0, lon0  : tensors in **degrees**  (any shape …)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    Returns:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        uv    : (..., 2)  where each component is in [-1,1]  (clipped)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        logJ  : (...)    log-Jacobian Δ(area_u,v) → Δ(area_lat,lon)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    lat_rad   = torch.deg2rad(lat)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    lat0_rad  = torch.deg2rad(lat0)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    # miles per degree (≈ 69 mi) and longitude scaling with cos(lat)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    R_mi      = 69.0\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    dx_mi     = R_mi * torch.cos(lat0_rad) * (lon - lon0)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    dy_mi     = R_mi * (lat - lat0)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    u         = dx_mi / half_side_mi\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    v         = dy_mi / half_side_mi\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    # ---------- Jacobian |∂(x,y)/∂(u,v)| = (half_side_mi)²\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    # plus lat scaling factors (R cosφ, R)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    logJ      = (\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        -2 * math.log(half_side_mi)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        - torch.log(R_mi * torch.cos(lat0_rad))\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        - math.log(R_mi)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    )\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    # ----- Option A: clip targets that wander outside the window\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    u_clipped = torch.clamp(u, -1.0, 1.0)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    v_clipped = torch.clamp(v, -1.0, 1.0)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    uv        = torch.stack([u_clipped, v_clipped], dim=-1)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    return uv, logJ\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# ============================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# 2) Load all cleaned-AIS parquet shards\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# ============================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mdef load_cleaned_data(cleaned_root: str) -> pl.DataFrame:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    p = Path(cleaned_root).resolve()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    files = list(p.rglob(\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m))\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    if not files:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        raise FileNotFoundError(f\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNo parquet files under \u001b[39;49m\u001b[38;5;132;43;01m{p}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    print(f\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m🟢 Reading \u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;124;43mlen(files)} parquet file(s)…\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, flush=True)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    return pl.read_parquet([str(f) for f in files])\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# ============================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# 3) Streaming dataset  (local-window version)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# ============================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mclass AISForecastIterableDataset(IterableDataset):\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    def __init__(self, df: pl.DataFrame, seq_len: int = 10, half_side_mi=50.0):\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        start = time.time()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        self.df = df.sort([\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmmsi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtimestamp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m])\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        self.mmsis = self.df[\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmmsi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m].unique().to_list()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        self.seq_len = seq_len\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        self.half_side_mi = half_side_mi\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        print(f\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m🟢 Dataset: \u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;124;43mlen(self.mmsis)} vessels loaded in \u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;124;43mtime.time()-start:.1f}s\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, flush=True)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    def __iter__(self):\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        for m in self.mmsis:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            grp = (\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                self.df\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                .filter(pl.col(\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmmsi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m) == m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                .select([\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlon\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m])\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            )\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            coords = torch.tensor(grp.to_numpy(), dtype=torch.float32)  # (N,2)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            N = coords.size(0)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            if N <= self.seq_len + 1:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                continue\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            # rolling windows\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            for i in range(self.seq_len, N - 1):\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                past_abs = coords[i - self.seq_len : i]   # (S,2)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                target_abs = coords[i]                    # (2,)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                lat0, lon0 = past_abs[-1]                 # window centre\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                past_uv, _     = latlon_to_local_uv(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                    past_abs[:, 0], past_abs[:, 1],\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                    lat0, lon0, self.half_side_mi\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                )\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                target_uv, logJ = latlon_to_local_uv(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                    target_abs[0], target_abs[1],\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                    lat0, lon0, self.half_side_mi\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                )\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                centre_ll_norm = torch.tensor([lat0 / 90.0, lon0 / 180.0])\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                yield (\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                    past_uv,              # (S,2)  local motion\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                    centre_ll_norm,       # (2,)    global context\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                    target_uv,            # (2,)    local target\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                    logJ                  # ()      log-Jacobian\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                )\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# ============================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# 4) Model  (local motion + global context)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# ============================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mclass TransformerForecaster(nn.Module):\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    def __init__(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        self,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        seq_len: int,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        d_model: int,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        nhead: int,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        num_layers: int,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        ff_hidden: int,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        fourier_m: int,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        rank: int,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    ):\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        super().__init__()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        self.seq_len = seq_len\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        # each timestep now has 4 features: (u,v, lat_norm, lon_norm)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        self.input_proj = nn.Linear(4, d_model)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        self.pos_emb = nn.Parameter(torch.randn(seq_len, d_model))\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        enc_layer = nn.TransformerEncoderLayer(d_model, nhead, ff_hidden)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        self.transformer = nn.TransformerEncoder(enc_layer, num_layers)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        self.fh = FourierHead2DLR(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            dim_input=d_model,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            num_frequencies=fourier_m,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            rank=rank\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        )\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    def forward(self, past_uv, centre_ll, target_uv):\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        past_uv   : (B, S, 2)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        centre_ll : (B, 2)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        target_uv : (B, 2)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        B, S, _ = past_uv.shape\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        # repeat centre_lat/lon to every timestep\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        centre_rep = centre_ll.unsqueeze(1).expand(-1, S, -1)  # (B,S,2)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        x = torch.cat([past_uv, centre_rep], dim=-1)           # (B,S,4)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        h = self.input_proj(x) + self.pos_emb.unsqueeze(0)     # (B,S,d)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        h = self.transformer(h.transpose(0, 1))                # (S,B,d)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        last = h[-1]                                           # (B,d)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        return self.fh(last, target_uv)                        # (B,)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# ============================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# 5) Training loop\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# ============================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mdef train(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    df: pl.DataFrame,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    seq_len: int = 10,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    d_model: int = 128,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    nhead: int = 4,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    num_layers: int = 4,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    ff_hidden: int = 512,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    fourier_m: int = 512,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    rank: int = 4,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    batch_size: int = 64,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    lr: float = 1e-3,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    epochs: int = 5,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    device: str | None = None,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m):\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    device = device or (\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m if torch.cuda.is_available() else \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    print(f\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m🟡 Training on \u001b[39;49m\u001b[38;5;132;43;01m{device}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, flush=True)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    ds = AISForecastIterableDataset(df, seq_len=seq_len)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    loader = DataLoader(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        ds, batch_size=batch_size, shuffle=False,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        drop_last=True, num_workers=0, pin_memory=True\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    )\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    model = TransformerForecaster(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        seq_len, d_model, nhead, num_layers,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        ff_hidden, fourier_m, rank\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    ).to(device)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    opt = optim.Adam(model.parameters(), lr=lr)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    for ep in range(1, epochs + 1):\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        total_nll, count = 0.0, 0\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        print(f\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mn🟡 Epoch \u001b[39;49m\u001b[38;5;132;43;01m{ep}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{epochs}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, flush=True)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        for b_idx, (past_uv, centre_ll, target_uv, logJ) in enumerate(loader, 1):\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            past_uv   = past_uv.to(device)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            centre_ll = centre_ll.to(device)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            target_uv = target_uv.to(device)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            logJ      = logJ.to(device)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            pdf_uv = model(past_uv, centre_ll, target_uv)      # (B,)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            # log-pdf in lat/lon space = log(pdf_uv) + logJ\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            loss   = -(torch.log(pdf_uv + 1e-12) + logJ).mean()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            opt.zero_grad()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            loss.backward()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            opt.step()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            total_nll += loss.item() * past_uv.size(0)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            count     += past_uv.size(0)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            if b_idx \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m 50 == 0:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                print(f\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m    Batch \u001b[39;49m\u001b[38;5;132;43;01m{b_idx}\u001b[39;49;00m\u001b[38;5;124;43m  NLL \u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;124;43mloss.item():.4f}\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, flush=True)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        print(f\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m🟢 Epoch \u001b[39;49m\u001b[38;5;132;43;01m{ep}\u001b[39;49;00m\u001b[38;5;124;43m  Avg NLL: \u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;124;43mtotal_nll / count:.4f}\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, flush=True)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    return model\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# ============================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# 6) Execute\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# ============================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mdf = load_cleaned_data(\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/cleaned_partitioned_ais\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mmodel = train(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    df,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    seq_len      = 20,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    d_model      = 128,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    nhead        = 4,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    num_layers   = 4,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    ff_hidden    = 512,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    fourier_m    = 64,     # local window → far fewer freqs needed\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    rank         = 4,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    batch_size   = 64,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    lr           = 1e-3,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    epochs       = 100,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mprint(\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m✅ Training complete\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, flush=True)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mPY\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2517\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2516\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2517\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2519\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2520\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/IPython/core/magics/script.py:154\u001b[0m, in \u001b[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m     line \u001b[38;5;241m=\u001b[39m script\n\u001b[0;32m--> 154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshebang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/IPython/core/magics/script.py:314\u001b[0m, in \u001b[0;36mScriptMagics.shebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mraise_error \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[1;32m    313\u001b[0m     rc \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'# \\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80 cell: end-to-end local-window training \\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\xe2\\x94\\x80\\n# Run this once; it replaces the previous \\xe2\\x80\\x9cglobal PDF\\xe2\\x80\\x9d cell.\\nset -euo pipefail\\npython - <<\\'PY\\'\\n# ------------------------------------------------------------\\n# 0) Imports  (all standard \\xe2\\x80\\x93 nothing beyond PyTorch & Polars)\\n# ------------------------------------------------------------\\nimport sys, time, math\\nfrom pathlib import Path\\n\\nimport polars as pl\\nimport torch\\nfrom torch import nn, optim\\nfrom torch.utils.data import IterableDataset, DataLoader\\n\\n# Make sure the Fourier-head repo is on path\\nfourier_dir = Path.home() / \"repos\" / \"fourier-head\" / \"notebooks\"\\nsys.path.insert(0, str(fourier_dir))\\nfrom four_head_2D_LR import FourierHead2DLR   # low-rank Fourier head\\n\\n# ============================================================\\n# 1) Utility: lat/lon  \\xe2\\x86\\x92  local (u,v)  in [-1,1]\\xc2\\xb2\\n# ============================================================\\ndef latlon_to_local_uv(lat, lon, lat0, lon0, half_side_mi=50.0):\\n    \"\"\"\\n    lat, lon, lat0, lon0  : tensors in **degrees**  (any shape \\xe2\\x80\\xa6)\\n    Returns:\\n        uv    : (..., 2)  where each component is in [-1,1]  (clipped)\\n        logJ  : (...)    log-Jacobian \\xce\\x94(area_u,v) \\xe2\\x86\\x92 \\xce\\x94(area_lat,lon)\\n    \"\"\"\\n    lat_rad   = torch.deg2rad(lat)\\n    lat0_rad  = torch.deg2rad(lat0)\\n\\n    # miles per degree (\\xe2\\x89\\x88 69 mi) and longitude scaling with cos(lat)\\n    R_mi      = 69.0\\n    dx_mi     = R_mi * torch.cos(lat0_rad) * (lon - lon0)\\n    dy_mi     = R_mi * (lat - lat0)\\n\\n    u         = dx_mi / half_side_mi\\n    v         = dy_mi / half_side_mi\\n\\n    # ---------- Jacobian |\\xe2\\x88\\x82(x,y)/\\xe2\\x88\\x82(u,v)| = (half_side_mi)\\xc2\\xb2\\n    # plus lat scaling factors (R cos\\xcf\\x86, R)\\n    logJ      = (\\n        -2 * math.log(half_side_mi)\\n        - torch.log(R_mi * torch.cos(lat0_rad))\\n        - math.log(R_mi)\\n    )\\n\\n    # ----- Option A: clip targets that wander outside the window\\n    u_clipped = torch.clamp(u, -1.0, 1.0)\\n    v_clipped = torch.clamp(v, -1.0, 1.0)\\n    uv        = torch.stack([u_clipped, v_clipped], dim=-1)\\n    return uv, logJ\\n\\n# ============================================================\\n# 2) Load all cleaned-AIS parquet shards\\n# ============================================================\\ndef load_cleaned_data(cleaned_root: str) -> pl.DataFrame:\\n    p = Path(cleaned_root).resolve()\\n    files = list(p.rglob(\"*.parquet\"))\\n    if not files:\\n        raise FileNotFoundError(f\"No parquet files under {p}\")\\n    print(f\"\\xf0\\x9f\\x9f\\xa2 Reading {len(files)} parquet file(s)\\xe2\\x80\\xa6\", flush=True)\\n    return pl.read_parquet([str(f) for f in files])\\n\\n# ============================================================\\n# 3) Streaming dataset  (local-window version)\\n# ============================================================\\nclass AISForecastIterableDataset(IterableDataset):\\n    def __init__(self, df: pl.DataFrame, seq_len: int = 10, half_side_mi=50.0):\\n        start = time.time()\\n        self.df = df.sort([\"mmsi\", \"timestamp\"])\\n        self.mmsis = self.df[\"mmsi\"].unique().to_list()\\n        self.seq_len = seq_len\\n        self.half_side_mi = half_side_mi\\n        print(f\"\\xf0\\x9f\\x9f\\xa2 Dataset: {len(self.mmsis)} vessels loaded in {time.time()-start:.1f}s\", flush=True)\\n\\n    def __iter__(self):\\n        for m in self.mmsis:\\n            grp = (\\n                self.df\\n                .filter(pl.col(\"mmsi\") == m)\\n                .select([\"lat\", \"lon\"])\\n            )\\n            coords = torch.tensor(grp.to_numpy(), dtype=torch.float32)  # (N,2)\\n            N = coords.size(0)\\n            if N <= self.seq_len + 1:\\n                continue\\n\\n            # rolling windows\\n            for i in range(self.seq_len, N - 1):\\n                past_abs = coords[i - self.seq_len : i]   # (S,2)\\n                target_abs = coords[i]                    # (2,)\\n\\n                lat0, lon0 = past_abs[-1]                 # window centre\\n                past_uv, _     = latlon_to_local_uv(\\n                    past_abs[:, 0], past_abs[:, 1],\\n                    lat0, lon0, self.half_side_mi\\n                )\\n                target_uv, logJ = latlon_to_local_uv(\\n                    target_abs[0], target_abs[1],\\n                    lat0, lon0, self.half_side_mi\\n                )\\n\\n                centre_ll_norm = torch.tensor([lat0 / 90.0, lon0 / 180.0])\\n\\n                yield (\\n                    past_uv,              # (S,2)  local motion\\n                    centre_ll_norm,       # (2,)    global context\\n                    target_uv,            # (2,)    local target\\n                    logJ                  # ()      log-Jacobian\\n                )\\n\\n# ============================================================\\n# 4) Model  (local motion + global context)\\n# ============================================================\\nclass TransformerForecaster(nn.Module):\\n    def __init__(\\n        self,\\n        seq_len: int,\\n        d_model: int,\\n        nhead: int,\\n        num_layers: int,\\n        ff_hidden: int,\\n        fourier_m: int,\\n        rank: int,\\n    ):\\n        super().__init__()\\n        self.seq_len = seq_len\\n\\n        # each timestep now has 4 features: (u,v, lat_norm, lon_norm)\\n        self.input_proj = nn.Linear(4, d_model)\\n        self.pos_emb = nn.Parameter(torch.randn(seq_len, d_model))\\n        enc_layer = nn.TransformerEncoderLayer(d_model, nhead, ff_hidden)\\n        self.transformer = nn.TransformerEncoder(enc_layer, num_layers)\\n        self.fh = FourierHead2DLR(\\n            dim_input=d_model,\\n            num_frequencies=fourier_m,\\n            rank=rank\\n        )\\n\\n    def forward(self, past_uv, centre_ll, target_uv):\\n        \"\"\"\\n        past_uv   : (B, S, 2)\\n        centre_ll : (B, 2)\\n        target_uv : (B, 2)\\n        \"\"\"\\n        B, S, _ = past_uv.shape\\n        # repeat centre_lat/lon to every timestep\\n        centre_rep = centre_ll.unsqueeze(1).expand(-1, S, -1)  # (B,S,2)\\n        x = torch.cat([past_uv, centre_rep], dim=-1)           # (B,S,4)\\n        h = self.input_proj(x) + self.pos_emb.unsqueeze(0)     # (B,S,d)\\n        h = self.transformer(h.transpose(0, 1))                # (S,B,d)\\n        last = h[-1]                                           # (B,d)\\n        return self.fh(last, target_uv)                        # (B,)\\n\\n# ============================================================\\n# 5) Training loop\\n# ============================================================\\ndef train(\\n    df: pl.DataFrame,\\n    seq_len: int = 10,\\n    d_model: int = 128,\\n    nhead: int = 4,\\n    num_layers: int = 4,\\n    ff_hidden: int = 512,\\n    fourier_m: int = 512,\\n    rank: int = 4,\\n    batch_size: int = 64,\\n    lr: float = 1e-3,\\n    epochs: int = 5,\\n    device: str | None = None,\\n):\\n    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n    print(f\"\\xf0\\x9f\\x9f\\xa1 Training on {device}\", flush=True)\\n\\n    ds = AISForecastIterableDataset(df, seq_len=seq_len)\\n    loader = DataLoader(\\n        ds, batch_size=batch_size, shuffle=False,\\n        drop_last=True, num_workers=0, pin_memory=True\\n    )\\n    model = TransformerForecaster(\\n        seq_len, d_model, nhead, num_layers,\\n        ff_hidden, fourier_m, rank\\n    ).to(device)\\n    opt = optim.Adam(model.parameters(), lr=lr)\\n\\n    for ep in range(1, epochs + 1):\\n        total_nll, count = 0.0, 0\\n        print(f\"\\\\n\\xf0\\x9f\\x9f\\xa1 Epoch {ep}/{epochs}\", flush=True)\\n\\n        for b_idx, (past_uv, centre_ll, target_uv, logJ) in enumerate(loader, 1):\\n            past_uv   = past_uv.to(device)\\n            centre_ll = centre_ll.to(device)\\n            target_uv = target_uv.to(device)\\n            logJ      = logJ.to(device)\\n\\n            pdf_uv = model(past_uv, centre_ll, target_uv)      # (B,)\\n            # log-pdf in lat/lon space = log(pdf_uv) + logJ\\n            loss   = -(torch.log(pdf_uv + 1e-12) + logJ).mean()\\n\\n            opt.zero_grad()\\n            loss.backward()\\n            opt.step()\\n\\n            total_nll += loss.item() * past_uv.size(0)\\n            count     += past_uv.size(0)\\n            if b_idx % 50 == 0:\\n                print(f\"    Batch {b_idx}  NLL {loss.item():.4f}\", flush=True)\\n\\n        print(f\"\\xf0\\x9f\\x9f\\xa2 Epoch {ep}  Avg NLL: {total_nll / count:.4f}\", flush=True)\\n\\n    return model\\n\\n# ============================================================\\n# 6) Execute\\n# ============================================================\\ndf = load_cleaned_data(\"data/cleaned_partitioned_ais\")\\nmodel = train(\\n    df,\\n    seq_len      = 20,\\n    d_model      = 128,\\n    nhead        = 4,\\n    num_layers   = 4,\\n    ff_hidden    = 512,\\n    fourier_m    = 64,     # local window \\xe2\\x86\\x92 far fewer freqs needed\\n    rank         = 4,\\n    batch_size   = 64,\\n    lr           = 1e-3,\\n    epochs       = 100,\\n)\\nprint(\"\\xe2\\x9c\\x85 Training complete\", flush=True)\\nPY\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# ─── cell: end-to-end local-window training ────────────────────────────────\n",
    "# Run this once; it replaces the previous “global PDF” cell.\n",
    "set -euo pipefail\n",
    "python - <<'PY'\n",
    "# ------------------------------------------------------------\n",
    "# 0) Imports  (all standard – nothing beyond PyTorch & Polars)\n",
    "# ------------------------------------------------------------\n",
    "import sys, time, math\n",
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "\n",
    "# Make sure the Fourier-head repo is on path\n",
    "fourier_dir = Path.home() / \"repos\" / \"fourier-head\" / \"notebooks\"\n",
    "sys.path.insert(0, str(fourier_dir))\n",
    "from four_head_2D_LR import FourierHead2DLR   # low-rank Fourier head\n",
    "\n",
    "# ============================================================\n",
    "# 1) Utility: lat/lon  →  local (u,v)  in [-1,1]²\n",
    "# ============================================================\n",
    "def latlon_to_local_uv(lat, lon, lat0, lon0, half_side_mi=50.0):\n",
    "    \"\"\"\n",
    "    lat, lon, lat0, lon0  : tensors in **degrees**  (any shape …)\n",
    "    Returns:\n",
    "        uv    : (..., 2)  where each component is in [-1,1]  (clipped)\n",
    "        logJ  : (...)    log-Jacobian Δ(area_u,v) → Δ(area_lat,lon)\n",
    "    \"\"\"\n",
    "    lat_rad   = torch.deg2rad(lat)\n",
    "    lat0_rad  = torch.deg2rad(lat0)\n",
    "\n",
    "    # miles per degree (≈ 69 mi) and longitude scaling with cos(lat)\n",
    "    R_mi      = 69.0\n",
    "    dx_mi     = R_mi * torch.cos(lat0_rad) * (lon - lon0)\n",
    "    dy_mi     = R_mi * (lat - lat0)\n",
    "\n",
    "    u         = dx_mi / half_side_mi\n",
    "    v         = dy_mi / half_side_mi\n",
    "\n",
    "    # ---------- Jacobian |∂(x,y)/∂(u,v)| = (half_side_mi)²\n",
    "    # plus lat scaling factors (R cosφ, R)\n",
    "    logJ      = (\n",
    "        -2 * math.log(half_side_mi)\n",
    "        - torch.log(R_mi * torch.cos(lat0_rad))\n",
    "        - math.log(R_mi)\n",
    "    )\n",
    "\n",
    "    # ----- Option A: clip targets that wander outside the window\n",
    "    u_clipped = torch.clamp(u, -1.0, 1.0)\n",
    "    v_clipped = torch.clamp(v, -1.0, 1.0)\n",
    "    uv        = torch.stack([u_clipped, v_clipped], dim=-1)\n",
    "    return uv, logJ\n",
    "\n",
    "# ============================================================\n",
    "# 2) Load all cleaned-AIS parquet shards\n",
    "# ============================================================\n",
    "def load_cleaned_data(cleaned_root: str) -> pl.DataFrame:\n",
    "    p = Path(cleaned_root).resolve()\n",
    "    files = list(p.rglob(\"*.parquet\"))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No parquet files under {p}\")\n",
    "    print(f\"🟢 Reading {len(files)} parquet file(s)…\", flush=True)\n",
    "    return pl.read_parquet([str(f) for f in files])\n",
    "\n",
    "# ============================================================\n",
    "# 3) Streaming dataset  (local-window version)\n",
    "# ============================================================\n",
    "class AISForecastIterableDataset(IterableDataset):\n",
    "    def __init__(self, df: pl.DataFrame, seq_len: int = 10, half_side_mi=50.0):\n",
    "        start = time.time()\n",
    "        self.df = df.sort([\"mmsi\", \"timestamp\"])\n",
    "        self.mmsis = self.df[\"mmsi\"].unique().to_list()\n",
    "        self.seq_len = seq_len\n",
    "        self.half_side_mi = half_side_mi\n",
    "        print(f\"🟢 Dataset: {len(self.mmsis)} vessels loaded in {time.time()-start:.1f}s\", flush=True)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for m in self.mmsis:\n",
    "            grp = (\n",
    "                self.df\n",
    "                .filter(pl.col(\"mmsi\") == m)\n",
    "                .select([\"lat\", \"lon\"])\n",
    "            )\n",
    "            coords = torch.tensor(grp.to_numpy(), dtype=torch.float32)  # (N,2)\n",
    "            N = coords.size(0)\n",
    "            if N <= self.seq_len + 1:\n",
    "                continue\n",
    "\n",
    "            # rolling windows\n",
    "            for i in range(self.seq_len, N - 1):\n",
    "                past_abs = coords[i - self.seq_len : i]   # (S,2)\n",
    "                target_abs = coords[i]                    # (2,)\n",
    "\n",
    "                lat0, lon0 = past_abs[-1]                 # window centre\n",
    "                past_uv, _     = latlon_to_local_uv(\n",
    "                    past_abs[:, 0], past_abs[:, 1],\n",
    "                    lat0, lon0, self.half_side_mi\n",
    "                )\n",
    "                target_uv, logJ = latlon_to_local_uv(\n",
    "                    target_abs[0], target_abs[1],\n",
    "                    lat0, lon0, self.half_side_mi\n",
    "                )\n",
    "\n",
    "                centre_ll_norm = torch.tensor([lat0 / 90.0, lon0 / 180.0])\n",
    "\n",
    "                yield (\n",
    "                    past_uv,              # (S,2)  local motion\n",
    "                    centre_ll_norm,       # (2,)    global context\n",
    "                    target_uv,            # (2,)    local target\n",
    "                    logJ                  # ()      log-Jacobian\n",
    "                )\n",
    "\n",
    "# ============================================================\n",
    "# 4) Model  (local motion + global context)\n",
    "# ============================================================\n",
    "class TransformerForecaster(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        seq_len: int,\n",
    "        d_model: int,\n",
    "        nhead: int,\n",
    "        num_layers: int,\n",
    "        ff_hidden: int,\n",
    "        fourier_m: int,\n",
    "        rank: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        # each timestep now has 4 features: (u,v, lat_norm, lon_norm)\n",
    "        self.input_proj = nn.Linear(4, d_model)\n",
    "        self.pos_emb = nn.Parameter(torch.randn(seq_len, d_model))\n",
    "        enc_layer = nn.TransformerEncoderLayer(d_model, nhead, ff_hidden)\n",
    "        self.transformer = nn.TransformerEncoder(enc_layer, num_layers)\n",
    "        self.fh = FourierHead2DLR(\n",
    "            dim_input=d_model,\n",
    "            num_frequencies=fourier_m,\n",
    "            rank=rank\n",
    "        )\n",
    "\n",
    "    def forward(self, past_uv, centre_ll, target_uv):\n",
    "        \"\"\"\n",
    "        past_uv   : (B, S, 2)\n",
    "        centre_ll : (B, 2)\n",
    "        target_uv : (B, 2)\n",
    "        \"\"\"\n",
    "        B, S, _ = past_uv.shape\n",
    "        # repeat centre_lat/lon to every timestep\n",
    "        centre_rep = centre_ll.unsqueeze(1).expand(-1, S, -1)  # (B,S,2)\n",
    "        x = torch.cat([past_uv, centre_rep], dim=-1)           # (B,S,4)\n",
    "        h = self.input_proj(x) + self.pos_emb.unsqueeze(0)     # (B,S,d)\n",
    "        h = self.transformer(h.transpose(0, 1))                # (S,B,d)\n",
    "        last = h[-1]                                           # (B,d)\n",
    "        return self.fh(last, target_uv)                        # (B,)\n",
    "\n",
    "# ============================================================\n",
    "# 5) Training loop\n",
    "# ============================================================\n",
    "def train(\n",
    "    df: pl.DataFrame,\n",
    "    seq_len: int = 10,\n",
    "    d_model: int = 128,\n",
    "    nhead: int = 4,\n",
    "    num_layers: int = 4,\n",
    "    ff_hidden: int = 512,\n",
    "    fourier_m: int = 512,\n",
    "    rank: int = 4,\n",
    "    batch_size: int = 64,\n",
    "    lr: float = 1e-3,\n",
    "    epochs: int = 5,\n",
    "    device: str | None = None,\n",
    "):\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"🟡 Training on {device}\", flush=True)\n",
    "\n",
    "    ds = AISForecastIterableDataset(df, seq_len=seq_len)\n",
    "    loader = DataLoader(\n",
    "        ds, batch_size=batch_size, shuffle=False,\n",
    "        drop_last=True, num_workers=0, pin_memory=True\n",
    "    )\n",
    "    model = TransformerForecaster(\n",
    "        seq_len, d_model, nhead, num_layers,\n",
    "        ff_hidden, fourier_m, rank\n",
    "    ).to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for ep in range(1, epochs + 1):\n",
    "        total_nll, count = 0.0, 0\n",
    "        print(f\"\\n🟡 Epoch {ep}/{epochs}\", flush=True)\n",
    "\n",
    "        for b_idx, (past_uv, centre_ll, target_uv, logJ) in enumerate(loader, 1):\n",
    "            past_uv   = past_uv.to(device)\n",
    "            centre_ll = centre_ll.to(device)\n",
    "            target_uv = target_uv.to(device)\n",
    "            logJ      = logJ.to(device)\n",
    "\n",
    "            pdf_uv = model(past_uv, centre_ll, target_uv)      # (B,)\n",
    "            # log-pdf in lat/lon space = log(pdf_uv) + logJ\n",
    "            loss   = -(torch.log(pdf_uv + 1e-12) + logJ).mean()\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            total_nll += loss.item() * past_uv.size(0)\n",
    "            count     += past_uv.size(0)\n",
    "            if b_idx % 50 == 0:\n",
    "                print(f\"    Batch {b_idx}  NLL {loss.item():.4f}\", flush=True)\n",
    "\n",
    "        print(f\"🟢 Epoch {ep}  Avg NLL: {total_nll / count:.4f}\", flush=True)\n",
    "\n",
    "    return model\n",
    "\n",
    "# ============================================================\n",
    "# 6) Execute\n",
    "# ============================================================\n",
    "df = load_cleaned_data(\"data/cleaned_partitioned_ais\")\n",
    "model = train(\n",
    "    df,\n",
    "    seq_len      = 20,\n",
    "    d_model      = 128,\n",
    "    nhead        = 4,\n",
    "    num_layers   = 4,\n",
    "    ff_hidden    = 512,\n",
    "    fourier_m    = 64,     # local window → far fewer freqs needed\n",
    "    rank         = 4,\n",
    "    batch_size   = 64,\n",
    "    lr           = 1e-3,\n",
    "    epochs       = 100,\n",
    ")\n",
    "print(\"✅ Training complete\", flush=True)\n",
    "PY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88246ab3-e3f7-41f7-8955-bfd774c0a12e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
